# Transportation-Data-Science-Project-by-NSDC

I built this project out of a simple but important question: how can data actually help make transportation systems safer, not just more efficient? Instead of treating crash data as just another dataset to model, I wanted to understand the real patterns behind when and where risks occur, especially when external factors like weather and time interact with transportation conditions.

For this project, I worked with large, multi-source datasets that included transportation and weather data. Like most real-world data, it wasn’t clean or perfectly structured. A big part of the work started with data cleaning, merging, and validation using Python (Pandas, NumPy) and SQL to ensure consistency across different sources. This meant handling missing values, aligning timestamps, and making sure the datasets could actually “talk” to each other before any meaningful analysis could begin. That preprocessing stage was honestly where most of the real analytical thinking happened.

Once the data pipeline was reliable, I moved into exploratory data analysis to understand underlying patterns. I used Python-based EDA, correlation analysis, and time-series exploration to identify temporal spikes in crash risks and how environmental factors might influence them. Instead of jumping straight into modeling, I focused on asking practical questions like: Are there specific time windows where incidents consistently increase? Do environmental conditions correlate with higher risk intervals? This approach helped ground the analysis in real-world interpretation rather than just technical outputs.

A key part of the project involved spatial analysis. Using Folium and geospatial visualization techniques, I created heatmaps to identify high-risk zones and visually communicate patterns that would be difficult to capture through tables alone. This was particularly useful in translating technical findings into insights that could be understood from a policy or planning perspective, which is something I’ve become increasingly interested in through my data science work.

I also applied time-series methods (including forecasting approaches like ARIMA/Prophet) to explore recurring risk patterns across different intervals. The goal wasn’t just prediction accuracy, but interpretability — understanding when risks might spike and how data-driven interventions could be scheduled more effectively. This aligns closely with how transportation analytics is used in practice, where actionable insights matter more than abstract model performance.

From a technical standpoint, this project reflects my full end-to-end workflow as a data analyst: data cleaning, multi-source integration, exploratory analysis, feature engineering, visualization, and insight communication, all developed in Python through Jupyter notebooks. It also strengthened my experience working with large, messy, real-world datasets rather than curated academic data, which required careful preprocessing and reproducible analytical pipelines.

More importantly, this project helped me develop stronger domain intuition in transportation and public safety analytics. Instead of viewing crashes as isolated events, I approached them as patterns influenced by environmental, temporal, and spatial factors. The final outcome was a set of data-driven insights highlighting high-risk zones, temporal risk intervals, and potential areas where targeted safety interventions could be prioritized.

Overall, it was a genuinely great experience learning, contributing, and working through a real problem in a practical setting. I enjoyed the process of exploring the data, iterating on ideas, and gradually seeing how small analytical steps can lead to more meaningful insights. Projects like this make the learning feel much more real and engaging compared to purely theoretical work, and they’ve definitely motivated me to keep working on similar data-driven, collaborative projects in the future. Always excited to learn more, build more, and collaborate more --- let’s gooo.
